{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf8zw53r5pH-",
        "outputId": "921e8731-ec67-404b-c525-dab5e14a46b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtfgm5IX6ygT",
        "outputId": "b0ffacf2-5ce7-473a-9b1c-2fa22a01cfd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split_folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split_folders\n",
            "Successfully installed split_folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "pip install split_folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zAFR0S_L660U"
      },
      "outputs": [],
      "source": [
        "import splitfolders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JcY-Y5QQ6-Kz"
      },
      "outputs": [],
      "source": [
        "input_folder=\"drive/MyDrive/malimg_paper_dataset_imgs\"\n",
        "output_folder=\"drive/MyDrive/newdata/data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljkUSex67BJ2",
        "outputId": "b84155e6-e469-444d-daf9-8328af85ea7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 1239 files [00:40, 30.51 files/s]\n"
          ]
        }
      ],
      "source": [
        "splitfolders.ratio(input_folder, output_folder, seed=42, ratio=(.6,.2, .2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odZhXp5R8-FP",
        "outputId": "8d930b2d-b2b6-4cd5-c449-c8a85c66ef78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.10/dist-packages (0.11.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from matplotlib-venn) (1.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->matplotlib-venn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->matplotlib-venn) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib-venn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0yq0khJ9BBP",
        "outputId": "6240e8f8-7f25-4b22-c99c-0acf9913db1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E: Package 'libfluidsynth1' has no installation candidate\n"
          ]
        }
      ],
      "source": [
        "!apt-get -qq install -y libfluidsynth1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.python.org/pypi/libarchive\n",
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "import libarchive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4mmIsLFhmay",
        "outputId": "f4dc08ec-e564-41e6-98ef-84ce6f07e8ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 122545 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.4.0-2ubuntu1.2_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.4.0-2ubuntu1.2) ...\n",
            "Setting up libarchive-dev:amd64 (3.4.0-2ubuntu1.2) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting libarchive\n",
            "  Downloading libarchive-0.4.7.tar.gz (23 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nose (from libarchive)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: libarchive\n",
            "  Building wheel for libarchive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libarchive: filename=libarchive-0.4.7-py3-none-any.whl size=31629 sha256=d181c7d64b503cc1fd01b0580cb1e9bb478e025da65f3ae1a2b3e72784157120\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/94/d0/6cd83c8a80a4236fd4cb2a1fd846ecf72ab1e0ac238c5951c0\n",
            "Successfully built libarchive\n",
            "Installing collected packages: nose, libarchive\n",
            "Successfully installed libarchive-0.4.7 nose-1.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import itertools\n",
        "import keras\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential \n",
        "from keras import optimizers\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Dropout, Flatten, Dense \n",
        "from keras import applications \n",
        "from keras.utils.np_utils import to_categorical \n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "import math \n",
        "import datetime\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from keras import callbacks\n",
        "from keras import optimizers\n",
        "#from keras.engine import Model\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#defining dimensions and locating files\n",
        "\n",
        "input_shape = (224,224, 3) \n",
        " \n",
        "#Creating a bottleneck file\n",
        "\n",
        "top_model_weights_path = \"bottleneck_fc_model.h5\"\n",
        "#top_model_weights_path = ‘bottleneck_fc_model.h5’\n",
        "# loading up our datasets\n",
        "train_data_dir = \"drive/MyDrive/newdata/data/train\"\n",
        "validation_data_dir = \"drive/MyDrive/newdata/data/val\" \n",
        "test_data_dir= \"drive/MyDrive/newdata/data/test\"\n",
        "#test_data_dir = ‘data/test’\n",
        "\n",
        "\n",
        "# number of epochs to train top model \n",
        "epochs = 100\n",
        "# batch size used by flow_from_directory and predict_generator \n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "8di-E99EhzCB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "QM1_TpuP5X2F",
        "outputId": "eca23ecb-2105-405b-adf3-703371f4b824"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7192bd7fd290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVGG19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'VGG19' from 'keras.applications' (/usr/local/lib/python3.7/dist-packages/keras/applications/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import itertools\n",
        "import keras\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img \n",
        "from keras.models import Sequential \n",
        "from keras import optimizers\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Dropout, Flatten, Dense \n",
        "from keras import applications \n",
        "from keras.utils.np_utils import to_categorical \n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "import math \n",
        "import datetime\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from keras import callbacks\n",
        "from keras import optimizers\n",
        "from keras.engine import Model\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#defining dimensions and locating files\n",
        "\n",
        "input_shape = (224,224, 3) \n",
        " \n",
        "#Creating a bottleneck file\n",
        "\n",
        "top_model_weights_path = \"bottleneck_fc_model.h5\"\n",
        "#top_model_weights_path = ‘bottleneck_fc_model.h5’\n",
        "# loading up our datasets\n",
        "train_data_dir = \"drive/MyDrive/newdata/data/train\"\n",
        "validation_data_dir = \"drive/MyDrive/newdata/data/val\" \n",
        "test_data_dir= \"drive/MyDrive/newdata/data/test\"\n",
        "#test_data_dir = ‘data/test’\n",
        "\n",
        "\n",
        "# number of epochs to train top model \n",
        "epochs = 100\n",
        "# batch size used by flow_from_directory and predict_generator \n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1_M1UAf9D9vk"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading VGG19 model\n",
        "from keras.applications import VGG19\n",
        "base_model = VGG19(input_shape = (224, 224, 3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')\n",
        "#base_model = VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "base_model.summary()\n",
        "#vgg16 = applications.VGG16(include_top=False, weights='imagenet')\n",
        "train_datagen = ImageDataGenerator( rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "    \n",
        "validation_datagen= ImageDataGenerator(rescale= 1./255 )\n",
        "test_datagen=ImageDataGenerator(rescale= 1./255 )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHmTCiIMiObc",
        "outputId": "c73ce2ec-3a6f-4b4f-ea86-9b52c8d548a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 1s 0us/step\n",
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekGP46lCEaGC",
        "outputId": "f64f8bcf-b108-4e35-bdaf-fbbf7adc4be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 674 images belonging to 63 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time:  0:08:41.623861\n"
          ]
        }
      ],
      "source": [
        "#__this can take an hour and half to run so only run it once. \n",
        "#once the npy files have been created, no need to run again. Convert this cell to a code cell to run.__\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "start = datetime.datetime.now()\n",
        " \n",
        "\n",
        " \n",
        "generator = train_datagen.flow_from_directory( \n",
        "    train_data_dir, \n",
        "    target_size=(224, 224), \n",
        "    batch_size=batch_size, \n",
        "    class_mode='categorical', \n",
        "    shuffle=False) \n",
        " \n",
        "nb_train_samples = len(generator.filenames) \n",
        "num_classes = len(generator.class_indices) \n",
        " \n",
        "predict_size_train = int(math.ceil(nb_train_samples / batch_size)) \n",
        " \n",
        "bottleneck_features_train = base_model.predict_generator(generator, predict_size_train) \n",
        " \n",
        "np.save(\"drive/MyDrive/ColabNotebooks/Data/bottleneck_features_train.npy\", bottleneck_features_train)\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ( \"Time: \", elapsed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcPpJwhQOIyo",
        "outputId": "6a2baf42-3f62-4a28-f3e5-42394af79ed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 674 images belonging to 63 classes.\n"
          ]
        }
      ],
      "source": [
        "#training data\n",
        "generator_top = train_datagen.flow_from_directory( \n",
        "   train_data_dir, \n",
        "   target_size=(224,244), \n",
        "   batch_size=batch_size, \n",
        "   class_mode=\"categorical\",\n",
        "   shuffle=False) \n",
        " \n",
        "nb_train_samples= len(generator_top.filenames) \n",
        "num_classes = len(generator_top.class_indices) \n",
        " \n",
        "# load the bottleneck features saved earlier \n",
        "train_data = np.load(\"drive/MyDrive/ColabNotebooks/Data/bottleneck_features_train.npy\") \n",
        " \n",
        "# get the class labels for the training data, in the original order \n",
        "train_labels = generator_top.classes \n",
        " \n",
        "# convert the training labels to categorical vectors \n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu2S47duGjbV",
        "outputId": "1fdaba8a-b1ad-48a1-8c78-9d929bdf68c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 311 images belonging to 63 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 22 batches). You may need to use the repeat() function when building your dataset.\n",
            "Time:  0:03:59.085335\n"
          ]
        }
      ],
      "source": [
        "#__this can take an hour and half to run so only run it once. \n",
        "#once the npy files have been created, no need to run again. Convert this cell to a code cell to run.__\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "start = datetime.datetime.now()\n",
        "  \n",
        "\n",
        " \n",
        "generator = validation_datagen.flow_from_directory( \n",
        "    validation_data_dir, \n",
        "    target_size=(224, 224), \n",
        "    batch_size=batch_size, \n",
        "    class_mode='categorical', \n",
        "    shuffle=False) \n",
        " \n",
        "nb_validation_samples = len(generator.filenames) \n",
        "num_classes = len(generator.class_indices) \n",
        " \n",
        "predict_size_validation = int(math.ceil(nb_train_samples / batch_size)) \n",
        " \n",
        "bottleneck_features_validation = base_model.predict_generator(generator, predict_size_validation) \n",
        " \n",
        "np.save(\"drive/MyDrive/ColabNotebooks/Data/bottleneck_features_validation.npy\", bottleneck_features_validation)\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ( \"Time: \", elapsed) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bASqAJKYPn3v",
        "outputId": "cbe12440-9419-4d29-b182-94c473a10cd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 311 images belonging to 63 classes.\n"
          ]
        }
      ],
      "source": [
        "generator_top = validation_datagen.flow_from_directory( \n",
        "   validation_data_dir, \n",
        "   #target_size=(224,224), \n",
        "   batch_size=batch_size, \n",
        "   class_mode=\"categorical\", \n",
        "   shuffle=False) \n",
        " \n",
        "nb_validation_samples = len(generator_top.filenames) \n",
        "num_classes = len(generator_top.class_indices) \n",
        " \n",
        "# load the bottleneck features saved earlier \n",
        "validation_data = np.load(\"drive/MyDrive/ColabNotebooks/Data/bottleneck_features_validation.npy\") \n",
        " \n",
        "# get the class labels for the testing data, in the original order \n",
        "validation_labels = generator_top.classes \n",
        " \n",
        "# convert the testing labels to categorical vectors \n",
        "validation_labels = to_categorical(validation_labels, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se0RtJ2GOEZZ",
        "outputId": "939b32f0-1feb-4a57-fdcb-93488cafad6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 207 images belonging to 63 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time:  0:02:40.284448\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "start = datetime.datetime.now()\n",
        " \n",
        "\n",
        " \n",
        "generator = test_datagen.flow_from_directory( \n",
        "    test_data_dir, \n",
        "    target_size=(224, 224), \n",
        "    batch_size=batch_size, \n",
        "    class_mode='categorical', \n",
        "    shuffle=False) \n",
        " \n",
        "nb_test_samples = len(generator.filenames) \n",
        "num_classes = len(generator.class_indices) \n",
        " \n",
        "predict_size_test = int(math.ceil(nb_test_samples / batch_size)) \n",
        " \n",
        "bottleneck_features_test = base_model.predict_generator(generator, predict_size_test) \n",
        " \n",
        "np.save(\"drive/MyDrive/ColabNotebooks/Data/bottleneck_features_test.npy\", bottleneck_features_test)\n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print ( \"Time: \", elapsed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmEd2wlWPVwR",
        "outputId": "aee03453-dcf7-4c11-eac1-25e7d39e561d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 86 images belonging to 25 classes.\n"
          ]
        }
      ],
      "source": [
        "generator_top = test_datagen.flow_from_directory( \n",
        "   test_data_dir, \n",
        "   #target_size=(224,224), \n",
        "   batch_size=batch_size, \n",
        "   class_mode=\"categorical\", \n",
        "   shuffle=False) \n",
        " \n",
        "nb_test_samples = len(generator_top.filenames) \n",
        "num_classes = len(generator_top.class_indices) \n",
        " \n",
        "# load the bottleneck features saved earlier \n",
        "test_data = np.load(\"drive/MyDrive/ColabNotebooks/Data/bottleneck_features_test.npy\") \n",
        " \n",
        "# get the class labels for the testing data, in the original order \n",
        "test_labels = generator_top.classes \n",
        " \n",
        "# convert the testing labels to categorical vectors \n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeqfwmWkP2oK",
        "outputId": "fc394079-eedb-46d2-fb09-736977d6f999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "8/8 [==============================] - 1s 46ms/step - loss: 0.4731 - accuracy: 0.3745 - val_loss: 0.1693 - val_accuracy: 0.9880\n",
            "Epoch 2/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.3099 - accuracy: 0.5737 - val_loss: 0.1199 - val_accuracy: 0.9880\n",
            "Epoch 3/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.2889 - accuracy: 0.6375 - val_loss: 0.0920 - val_accuracy: 0.9880\n",
            "Epoch 4/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2659 - accuracy: 0.7291 - val_loss: 0.0780 - val_accuracy: 0.9880\n",
            "Epoch 5/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2535 - accuracy: 0.6932 - val_loss: 0.0694 - val_accuracy: 0.9880\n",
            "Epoch 6/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2355 - accuracy: 0.6653 - val_loss: 0.0560 - val_accuracy: 0.9880\n",
            "Epoch 7/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2242 - accuracy: 0.7131 - val_loss: 0.0505 - val_accuracy: 0.9880\n",
            "Epoch 8/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2207 - accuracy: 0.7171 - val_loss: 0.0433 - val_accuracy: 0.9880\n",
            "Epoch 9/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.2112 - accuracy: 0.7371 - val_loss: 0.0379 - val_accuracy: 0.9880\n",
            "Epoch 10/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1893 - accuracy: 0.8127 - val_loss: 0.0334 - val_accuracy: 0.9880\n",
            "Epoch 11/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1989 - accuracy: 0.8127 - val_loss: 0.0305 - val_accuracy: 0.9880\n",
            "Epoch 12/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.1765 - accuracy: 0.7928 - val_loss: 0.0257 - val_accuracy: 0.9880\n",
            "Epoch 13/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1759 - accuracy: 0.8167 - val_loss: 0.0225 - val_accuracy: 0.9880\n",
            "Epoch 14/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1769 - accuracy: 0.7928 - val_loss: 0.0211 - val_accuracy: 0.9880\n",
            "Epoch 15/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1588 - accuracy: 0.8486 - val_loss: 0.0189 - val_accuracy: 0.9880\n",
            "Epoch 16/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.1482 - accuracy: 0.8446 - val_loss: 0.0164 - val_accuracy: 0.9880\n",
            "Epoch 17/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1554 - accuracy: 0.8367 - val_loss: 0.0160 - val_accuracy: 0.9880\n",
            "Epoch 18/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1435 - accuracy: 0.8685 - val_loss: 0.0149 - val_accuracy: 0.9880\n",
            "Epoch 19/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1482 - accuracy: 0.8367 - val_loss: 0.0136 - val_accuracy: 0.9880\n",
            "Epoch 20/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1447 - accuracy: 0.8566 - val_loss: 0.0127 - val_accuracy: 0.9880\n",
            "Epoch 21/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1420 - accuracy: 0.8526 - val_loss: 0.0123 - val_accuracy: 0.9880\n",
            "Epoch 22/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.1219 - accuracy: 0.9004 - val_loss: 0.0112 - val_accuracy: 0.9880\n",
            "Epoch 23/200\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.1278 - accuracy: 0.8765 - val_loss: 0.0110 - val_accuracy: 0.9880\n",
            "Epoch 24/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1091 - accuracy: 0.8606 - val_loss: 0.0105 - val_accuracy: 0.9880\n",
            "Epoch 25/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1103 - accuracy: 0.8845 - val_loss: 0.0099 - val_accuracy: 0.9880\n",
            "Epoch 26/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.1205 - accuracy: 0.8765 - val_loss: 0.0097 - val_accuracy: 0.9880\n",
            "Epoch 27/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1076 - accuracy: 0.8964 - val_loss: 0.0094 - val_accuracy: 0.9880\n",
            "Epoch 28/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1029 - accuracy: 0.9044 - val_loss: 0.0089 - val_accuracy: 0.9880\n",
            "Epoch 29/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0963 - accuracy: 0.8884 - val_loss: 0.0084 - val_accuracy: 0.9880\n",
            "Epoch 30/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0961 - accuracy: 0.9323 - val_loss: 0.0084 - val_accuracy: 0.9880\n",
            "Epoch 31/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1004 - accuracy: 0.9163 - val_loss: 0.0083 - val_accuracy: 0.9880\n",
            "Epoch 32/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0961 - accuracy: 0.9283 - val_loss: 0.0082 - val_accuracy: 0.9880\n",
            "Epoch 33/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0815 - accuracy: 0.9243 - val_loss: 0.0080 - val_accuracy: 0.9880\n",
            "Epoch 34/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0749 - accuracy: 0.9602 - val_loss: 0.0079 - val_accuracy: 0.9880\n",
            "Epoch 35/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0813 - accuracy: 0.9084 - val_loss: 0.0078 - val_accuracy: 0.9880\n",
            "Epoch 36/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0794 - accuracy: 0.9124 - val_loss: 0.0076 - val_accuracy: 0.9880\n",
            "Epoch 37/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0813 - accuracy: 0.9363 - val_loss: 0.0076 - val_accuracy: 0.9880\n",
            "Epoch 38/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0804 - accuracy: 0.9363 - val_loss: 0.0074 - val_accuracy: 0.9880\n",
            "Epoch 39/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0802 - accuracy: 0.9203 - val_loss: 0.0074 - val_accuracy: 0.9880\n",
            "Epoch 40/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0700 - accuracy: 0.9243 - val_loss: 0.0074 - val_accuracy: 0.9880\n",
            "Epoch 41/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0745 - accuracy: 0.9402 - val_loss: 0.0073 - val_accuracy: 0.9880\n",
            "Epoch 42/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0858 - accuracy: 0.9363 - val_loss: 0.0071 - val_accuracy: 0.9880\n",
            "Epoch 43/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0772 - accuracy: 0.9203 - val_loss: 0.0072 - val_accuracy: 0.9880\n",
            "Epoch 44/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0776 - accuracy: 0.9442 - val_loss: 0.0072 - val_accuracy: 0.9880\n",
            "Epoch 45/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0757 - accuracy: 0.9243 - val_loss: 0.0073 - val_accuracy: 0.9880\n",
            "Epoch 46/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0711 - accuracy: 0.9482 - val_loss: 0.0072 - val_accuracy: 0.9880\n",
            "Epoch 47/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0711 - accuracy: 0.9482 - val_loss: 0.0071 - val_accuracy: 0.9880\n",
            "Epoch 48/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0625 - accuracy: 0.9641 - val_loss: 0.0070 - val_accuracy: 0.9880\n",
            "Epoch 49/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0677 - accuracy: 0.9522 - val_loss: 0.0072 - val_accuracy: 0.9880\n",
            "Epoch 50/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0654 - accuracy: 0.9402 - val_loss: 0.0070 - val_accuracy: 0.9880\n",
            "Epoch 51/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0586 - accuracy: 0.9442 - val_loss: 0.0071 - val_accuracy: 0.9880\n",
            "Epoch 52/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0603 - accuracy: 0.9562 - val_loss: 0.0069 - val_accuracy: 0.9880\n",
            "Epoch 53/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0697 - accuracy: 0.9522 - val_loss: 0.0069 - val_accuracy: 0.9880\n",
            "Epoch 54/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0600 - accuracy: 0.9522 - val_loss: 0.0070 - val_accuracy: 0.9880\n",
            "Epoch 55/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0508 - accuracy: 0.9602 - val_loss: 0.0068 - val_accuracy: 0.9880\n",
            "Epoch 56/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0582 - accuracy: 0.9602 - val_loss: 0.0069 - val_accuracy: 0.9880\n",
            "Epoch 57/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0611 - accuracy: 0.9522 - val_loss: 0.0072 - val_accuracy: 0.9880\n",
            "Epoch 58/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0513 - accuracy: 0.9681 - val_loss: 0.0071 - val_accuracy: 0.9880\n",
            "Epoch 59/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0493 - accuracy: 0.9761 - val_loss: 0.0071 - val_accuracy: 0.9880\n",
            "Epoch 60/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0555 - accuracy: 0.9602 - val_loss: 0.0071 - val_accuracy: 0.9880\n",
            "Epoch 61/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0673 - accuracy: 0.9402 - val_loss: 0.0069 - val_accuracy: 0.9880\n",
            "Epoch 62/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0476 - accuracy: 0.9641 - val_loss: 0.0070 - val_accuracy: 0.9880\n",
            "Epoch 63/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0548 - accuracy: 0.9522 - val_loss: 0.0071 - val_accuracy: 0.9880\n",
            "Epoch 64/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0549 - accuracy: 0.9641 - val_loss: 0.0069 - val_accuracy: 0.9880\n",
            "Epoch 65/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0513 - accuracy: 0.9602 - val_loss: 0.0068 - val_accuracy: 0.9880\n",
            "Epoch 66/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0560 - accuracy: 0.9641 - val_loss: 0.0068 - val_accuracy: 0.9880\n",
            "Epoch 67/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0590 - accuracy: 0.9482 - val_loss: 0.0069 - val_accuracy: 0.9880\n",
            "Epoch 68/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0461 - accuracy: 0.9641 - val_loss: 0.0068 - val_accuracy: 0.9880\n",
            "Epoch 69/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0581 - accuracy: 0.9522 - val_loss: 0.0067 - val_accuracy: 0.9880\n",
            "Epoch 70/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0553 - accuracy: 0.9721 - val_loss: 0.0067 - val_accuracy: 0.9880\n",
            "Epoch 71/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0520 - accuracy: 0.9602 - val_loss: 0.0068 - val_accuracy: 0.9880\n",
            "Epoch 72/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0488 - accuracy: 0.9522 - val_loss: 0.0067 - val_accuracy: 0.9880\n",
            "Epoch 73/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0481 - accuracy: 0.9641 - val_loss: 0.0068 - val_accuracy: 0.9880\n",
            "Epoch 74/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0529 - accuracy: 0.9562 - val_loss: 0.0066 - val_accuracy: 0.9880\n",
            "Epoch 75/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0444 - accuracy: 0.9482 - val_loss: 0.0067 - val_accuracy: 0.9880\n",
            "Epoch 76/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0421 - accuracy: 0.9522 - val_loss: 0.0067 - val_accuracy: 0.9880\n",
            "Epoch 77/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0429 - accuracy: 0.9641 - val_loss: 0.0068 - val_accuracy: 0.9880\n",
            "Epoch 78/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0465 - accuracy: 0.9602 - val_loss: 0.0067 - val_accuracy: 0.9880\n",
            "Epoch 79/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0347 - accuracy: 0.9721 - val_loss: 0.0067 - val_accuracy: 0.9880\n",
            "Epoch 80/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0360 - accuracy: 0.9761 - val_loss: 0.0068 - val_accuracy: 0.9880\n",
            "Epoch 81/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0429 - accuracy: 0.9761 - val_loss: 0.0067 - val_accuracy: 0.9880\n",
            "Epoch 82/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0441 - accuracy: 0.9562 - val_loss: 0.0068 - val_accuracy: 0.9880\n",
            "Epoch 83/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0403 - accuracy: 0.9602 - val_loss: 0.0068 - val_accuracy: 0.9880\n",
            "Epoch 84/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0428 - accuracy: 0.9641 - val_loss: 0.0066 - val_accuracy: 0.9880\n",
            "Epoch 85/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0415 - accuracy: 0.9721 - val_loss: 0.0066 - val_accuracy: 0.9880\n",
            "Epoch 86/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0361 - accuracy: 0.9363 - val_loss: 0.0068 - val_accuracy: 0.9880\n",
            "Epoch 87/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0547 - accuracy: 0.9562 - val_loss: 0.0068 - val_accuracy: 0.9880\n",
            "Epoch 88/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0447 - accuracy: 0.9761 - val_loss: 0.0068 - val_accuracy: 0.9880\n",
            "Epoch 89/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0374 - accuracy: 0.9602 - val_loss: 0.0067 - val_accuracy: 0.9880\n",
            "Epoch 90/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0412 - accuracy: 0.9721 - val_loss: 0.0067 - val_accuracy: 0.9880\n",
            "Epoch 91/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0314 - accuracy: 0.9721 - val_loss: 0.0066 - val_accuracy: 0.9880\n",
            "Epoch 92/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0352 - accuracy: 0.9681 - val_loss: 0.0065 - val_accuracy: 0.9880\n",
            "Epoch 93/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0341 - accuracy: 0.9681 - val_loss: 0.0065 - val_accuracy: 0.9880\n",
            "Epoch 94/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0331 - accuracy: 0.9721 - val_loss: 0.0065 - val_accuracy: 0.9880\n",
            "Epoch 95/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0306 - accuracy: 0.9681 - val_loss: 0.0066 - val_accuracy: 0.9880\n",
            "Epoch 96/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0341 - accuracy: 0.9761 - val_loss: 0.0067 - val_accuracy: 0.9880\n",
            "Epoch 97/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0363 - accuracy: 0.9562 - val_loss: 0.0066 - val_accuracy: 0.9880\n",
            "Epoch 98/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0367 - accuracy: 0.9641 - val_loss: 0.0068 - val_accuracy: 0.9880\n",
            "Epoch 99/200\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0356 - accuracy: 0.9761 - val_loss: 0.0066 - val_accuracy: 0.9880\n",
            "Epoch 100/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0397 - accuracy: 0.9641 - val_loss: 0.0065 - val_accuracy: 0.9880\n",
            "Epoch 101/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0327 - accuracy: 0.9761 - val_loss: 0.0065 - val_accuracy: 0.9880\n",
            "Epoch 102/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0370 - accuracy: 0.9602 - val_loss: 0.0065 - val_accuracy: 0.9880\n",
            "Epoch 103/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0353 - accuracy: 0.9522 - val_loss: 0.0065 - val_accuracy: 0.9880\n",
            "Epoch 104/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0333 - accuracy: 0.9761 - val_loss: 0.0064 - val_accuracy: 0.9880\n",
            "Epoch 105/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0403 - accuracy: 0.9602 - val_loss: 0.0065 - val_accuracy: 0.9880\n",
            "Epoch 106/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0295 - accuracy: 0.9721 - val_loss: 0.0065 - val_accuracy: 0.9880\n",
            "Epoch 107/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0316 - accuracy: 0.9761 - val_loss: 0.0066 - val_accuracy: 0.9880\n",
            "Epoch 108/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0333 - accuracy: 0.9761 - val_loss: 0.0065 - val_accuracy: 0.9880\n",
            "Epoch 109/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0333 - accuracy: 0.9681 - val_loss: 0.0064 - val_accuracy: 0.9880\n",
            "Epoch 110/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0389 - accuracy: 0.9641 - val_loss: 0.0065 - val_accuracy: 0.9880\n",
            "Epoch 111/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0317 - accuracy: 0.9761 - val_loss: 0.0064 - val_accuracy: 0.9880\n",
            "Epoch 112/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0337 - accuracy: 0.9721 - val_loss: 0.0065 - val_accuracy: 0.9880\n",
            "Epoch 113/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0304 - accuracy: 0.9681 - val_loss: 0.0063 - val_accuracy: 0.9880\n",
            "Epoch 114/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0313 - accuracy: 0.9681 - val_loss: 0.0062 - val_accuracy: 0.9880\n",
            "Epoch 115/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0321 - accuracy: 0.9801 - val_loss: 0.0062 - val_accuracy: 0.9880\n",
            "Epoch 116/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0303 - accuracy: 0.9761 - val_loss: 0.0060 - val_accuracy: 0.9880\n",
            "Epoch 117/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0359 - accuracy: 0.9761 - val_loss: 0.0061 - val_accuracy: 0.9880\n",
            "Epoch 118/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0322 - accuracy: 0.9761 - val_loss: 0.0060 - val_accuracy: 0.9880\n",
            "Epoch 119/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0275 - accuracy: 0.9841 - val_loss: 0.0060 - val_accuracy: 0.9880\n",
            "Epoch 120/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0322 - accuracy: 0.9761 - val_loss: 0.0060 - val_accuracy: 0.9880\n",
            "Epoch 121/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0310 - accuracy: 0.9801 - val_loss: 0.0060 - val_accuracy: 0.9880\n",
            "Epoch 122/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0278 - accuracy: 0.9721 - val_loss: 0.0061 - val_accuracy: 0.9880\n",
            "Epoch 123/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0320 - accuracy: 0.9761 - val_loss: 0.0061 - val_accuracy: 0.9880\n",
            "Epoch 124/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0246 - accuracy: 0.9761 - val_loss: 0.0060 - val_accuracy: 0.9880\n",
            "Epoch 125/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0248 - accuracy: 0.9681 - val_loss: 0.0061 - val_accuracy: 0.9880\n",
            "Epoch 126/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0290 - accuracy: 0.9801 - val_loss: 0.0060 - val_accuracy: 0.9880\n",
            "Epoch 127/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0255 - accuracy: 0.9761 - val_loss: 0.0061 - val_accuracy: 0.9880\n",
            "Epoch 128/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0207 - accuracy: 0.9761 - val_loss: 0.0061 - val_accuracy: 0.9880\n",
            "Epoch 129/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0312 - accuracy: 0.9761 - val_loss: 0.0062 - val_accuracy: 0.9880\n",
            "Epoch 130/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0244 - accuracy: 0.9721 - val_loss: 0.0061 - val_accuracy: 0.9880\n",
            "Epoch 131/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0262 - accuracy: 0.9801 - val_loss: 0.0060 - val_accuracy: 0.9880\n",
            "Epoch 132/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0289 - accuracy: 0.9721 - val_loss: 0.0059 - val_accuracy: 0.9880\n",
            "Epoch 133/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0260 - accuracy: 0.9761 - val_loss: 0.0059 - val_accuracy: 0.9880\n",
            "Epoch 134/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0314 - accuracy: 0.9801 - val_loss: 0.0061 - val_accuracy: 0.9880\n",
            "Epoch 135/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0255 - accuracy: 0.9721 - val_loss: 0.0062 - val_accuracy: 0.9880\n",
            "Epoch 136/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0242 - accuracy: 0.9801 - val_loss: 0.0059 - val_accuracy: 0.9880\n",
            "Epoch 137/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0266 - accuracy: 0.9721 - val_loss: 0.0060 - val_accuracy: 0.9880\n",
            "Epoch 138/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0245 - accuracy: 0.9761 - val_loss: 0.0060 - val_accuracy: 0.9880\n",
            "Epoch 139/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0301 - accuracy: 0.9841 - val_loss: 0.0060 - val_accuracy: 0.9880\n",
            "Epoch 140/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0303 - accuracy: 0.9721 - val_loss: 0.0060 - val_accuracy: 0.9880\n",
            "Epoch 141/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0218 - accuracy: 0.9801 - val_loss: 0.0060 - val_accuracy: 0.9880\n",
            "Epoch 142/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0268 - accuracy: 0.9721 - val_loss: 0.0059 - val_accuracy: 0.9880\n",
            "Epoch 143/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0277 - accuracy: 0.9761 - val_loss: 0.0059 - val_accuracy: 0.9880\n",
            "Epoch 144/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0186 - accuracy: 0.9761 - val_loss: 0.0059 - val_accuracy: 0.9880\n",
            "Epoch 145/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0259 - accuracy: 0.9801 - val_loss: 0.0059 - val_accuracy: 0.9880\n",
            "Epoch 146/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0304 - accuracy: 0.9681 - val_loss: 0.0058 - val_accuracy: 0.9880\n",
            "Epoch 147/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0231 - accuracy: 0.9801 - val_loss: 0.0059 - val_accuracy: 0.9880\n",
            "Epoch 148/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0314 - accuracy: 0.9761 - val_loss: 0.0059 - val_accuracy: 0.9880\n",
            "Epoch 149/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0249 - accuracy: 0.9801 - val_loss: 0.0057 - val_accuracy: 0.9880\n",
            "Epoch 150/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0226 - accuracy: 0.9641 - val_loss: 0.0058 - val_accuracy: 0.9880\n",
            "Epoch 151/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0277 - accuracy: 0.9602 - val_loss: 0.0059 - val_accuracy: 0.9880\n",
            "Epoch 152/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0238 - accuracy: 0.9761 - val_loss: 0.0057 - val_accuracy: 0.9880\n",
            "Epoch 153/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0261 - accuracy: 0.9801 - val_loss: 0.0057 - val_accuracy: 0.9880\n",
            "Epoch 154/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0230 - accuracy: 0.9841 - val_loss: 0.0057 - val_accuracy: 0.9880\n",
            "Epoch 155/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0223 - accuracy: 0.9761 - val_loss: 0.0057 - val_accuracy: 0.9880\n",
            "Epoch 156/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0255 - accuracy: 0.9761 - val_loss: 0.0057 - val_accuracy: 0.9880\n",
            "Epoch 157/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0291 - accuracy: 0.9721 - val_loss: 0.0057 - val_accuracy: 0.9880\n",
            "Epoch 158/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0242 - accuracy: 0.9761 - val_loss: 0.0056 - val_accuracy: 0.9880\n",
            "Epoch 159/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0236 - accuracy: 0.9721 - val_loss: 0.0056 - val_accuracy: 0.9880\n",
            "Epoch 160/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0253 - accuracy: 0.9761 - val_loss: 0.0056 - val_accuracy: 0.9880\n",
            "Epoch 161/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0201 - accuracy: 0.9721 - val_loss: 0.0057 - val_accuracy: 0.9880\n",
            "Epoch 162/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0256 - accuracy: 0.9801 - val_loss: 0.0056 - val_accuracy: 0.9880\n",
            "Epoch 163/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0197 - accuracy: 0.9801 - val_loss: 0.0056 - val_accuracy: 0.9880\n",
            "Epoch 164/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0228 - accuracy: 0.9761 - val_loss: 0.0055 - val_accuracy: 0.9880\n",
            "Epoch 165/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0256 - accuracy: 0.9761 - val_loss: 0.0055 - val_accuracy: 0.9880\n",
            "Epoch 166/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0224 - accuracy: 0.9761 - val_loss: 0.0056 - val_accuracy: 0.9880\n",
            "Epoch 167/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0215 - accuracy: 0.9801 - val_loss: 0.0056 - val_accuracy: 0.9880\n",
            "Epoch 168/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0247 - accuracy: 0.9761 - val_loss: 0.0056 - val_accuracy: 0.9880\n",
            "Epoch 169/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0244 - accuracy: 0.9841 - val_loss: 0.0055 - val_accuracy: 0.9880\n",
            "Epoch 170/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0254 - accuracy: 0.9761 - val_loss: 0.0054 - val_accuracy: 0.9880\n",
            "Epoch 171/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0254 - accuracy: 0.9721 - val_loss: 0.0054 - val_accuracy: 0.9880\n",
            "Epoch 172/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0232 - accuracy: 0.9801 - val_loss: 0.0053 - val_accuracy: 0.9880\n",
            "Epoch 173/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0234 - accuracy: 0.9801 - val_loss: 0.0052 - val_accuracy: 0.9880\n",
            "Epoch 174/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0263 - accuracy: 0.9801 - val_loss: 0.0053 - val_accuracy: 0.9880\n",
            "Epoch 175/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0189 - accuracy: 0.9841 - val_loss: 0.0053 - val_accuracy: 0.9880\n",
            "Epoch 176/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0259 - accuracy: 0.9761 - val_loss: 0.0054 - val_accuracy: 0.9880\n",
            "Epoch 177/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0198 - accuracy: 0.9801 - val_loss: 0.0052 - val_accuracy: 0.9880\n",
            "Epoch 178/200\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.0195 - accuracy: 0.9841 - val_loss: 0.0052 - val_accuracy: 0.9880\n",
            "Epoch 179/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0224 - accuracy: 0.9801 - val_loss: 0.0052 - val_accuracy: 0.9880\n",
            "Epoch 180/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0209 - accuracy: 0.9841 - val_loss: 0.0050 - val_accuracy: 0.9880\n",
            "Epoch 181/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0246 - accuracy: 0.9721 - val_loss: 0.0050 - val_accuracy: 0.9880\n",
            "Epoch 182/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0195 - accuracy: 0.9841 - val_loss: 0.0051 - val_accuracy: 0.9880\n",
            "Epoch 183/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0214 - accuracy: 0.9721 - val_loss: 0.0052 - val_accuracy: 0.9880\n",
            "Epoch 184/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0214 - accuracy: 0.9880 - val_loss: 0.0052 - val_accuracy: 0.9880\n",
            "Epoch 185/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0187 - accuracy: 0.9801 - val_loss: 0.0052 - val_accuracy: 0.9880\n",
            "Epoch 186/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0217 - accuracy: 0.9761 - val_loss: 0.0051 - val_accuracy: 0.9880\n",
            "Epoch 187/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0236 - accuracy: 0.9761 - val_loss: 0.0050 - val_accuracy: 0.9880\n",
            "Epoch 188/200\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0211 - accuracy: 0.9801 - val_loss: 0.0051 - val_accuracy: 0.9880\n",
            "Epoch 189/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0197 - accuracy: 0.9801 - val_loss: 0.0052 - val_accuracy: 0.9880\n",
            "Epoch 190/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0198 - accuracy: 0.9801 - val_loss: 0.0053 - val_accuracy: 0.9880\n",
            "Epoch 191/200\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.0222 - accuracy: 0.9681 - val_loss: 0.0052 - val_accuracy: 0.9880\n",
            "Epoch 192/200\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0202 - accuracy: 0.9761 - val_loss: 0.0050 - val_accuracy: 0.9880\n",
            "Epoch 193/200\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.0205 - accuracy: 0.9761 - val_loss: 0.0049 - val_accuracy: 0.9880\n",
            "Epoch 194/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0227 - accuracy: 0.9761 - val_loss: 0.0048 - val_accuracy: 0.9880\n",
            "Epoch 195/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0211 - accuracy: 0.9801 - val_loss: 0.0049 - val_accuracy: 0.9880\n",
            "Epoch 196/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0251 - accuracy: 0.9801 - val_loss: 0.0048 - val_accuracy: 0.9880\n",
            "Epoch 197/200\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0200 - accuracy: 0.9841 - val_loss: 0.0048 - val_accuracy: 0.9880\n",
            "Epoch 198/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0181 - accuracy: 0.9841 - val_loss: 0.0049 - val_accuracy: 0.9880\n",
            "Epoch 199/200\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.0200 - accuracy: 0.9841 - val_loss: 0.0049 - val_accuracy: 0.9880\n",
            "Epoch 200/200\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.0197 - accuracy: 0.9761 - val_loss: 0.0049 - val_accuracy: 0.9880\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.0049 - accuracy: 0.9880\n",
            "[INFO] accuracy: 98.80%\n",
            "[INFO] Loss: 0.004930507857352495\n",
            "Time:  0:00:41.687179\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Conv2D, ReLU,MaxPool2D\n",
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils\n",
        "\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "model = Sequential() \n",
        "#model.add(Conv2D(64, (3,3)))\n",
        "\n",
        "#model.add(MaxPool2D(pool_size=(1,1)))\n",
        "\n",
        "#model.add(Conv2D(128, (3,3)))\n",
        "\n",
        "#model.add(MaxPool2D(pool_size=(1,1)))\n",
        "\n",
        "#model.add(Conv2D(256, (3,3)))\n",
        "\n",
        "#model.add(MaxPool2D(pool_size=(1,1)))\n",
        "\n",
        "\n",
        "\n",
        "#now through flatten we are converting our 2D image to 1D image\n",
        "model.add(Flatten())\n",
        "model.add(Flatten(input_shape=train_data.shape[1:])) \n",
        "#model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(100, activation=keras.layers.LeakyReLU(alpha=0.3))) \n",
        "model.add(Dropout(0.75)) \n",
        "#model.add(Dense(50, activation=keras.layers.LeakyReLU(alpha=0.3))) \n",
        "\n",
        "#model.add(Dense(64, activation='relu'))\n",
        "#model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "\n",
        "\n",
        "#model.add(Dropout(0.5)) \n",
        "#model.compile(optimizer=RMSprop(lr=0.001, decay=0.0001/100), loss= tf.keras.losses.CategoricalCrossentropy(\n",
        " #   from_logits=False, label_smoothing=0,\n",
        "  #  name='sparse_categorical_crossentropy'), metrics=['accuracy'])\n",
        "#model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='rmsPROP(lr=0.001)')\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels, \n",
        "   epochs=200,\n",
        "   batch_size=batch_size, \n",
        "   validation_data=(validation_data, validation_labels))\n",
        "model.save_weights(top_model_weights_path)\n",
        "(eval_loss, eval_accuracy) = model.evaluate( \n",
        "    validation_data, validation_labels, batch_size=batch_size,     verbose=1)\n",
        "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100)) \n",
        "print(\"[INFO] Loss: {}\".format(eval_loss)) \n",
        "end= datetime.datetime.now()\n",
        "elapsed= end-start\n",
        "print (\"Time: \", elapsed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "Kk9VCMlKRcnU",
        "outputId": "ca2702d9-a6d9-4267-b2a8-aee221045827"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#finding the graphs of training and validation\n",
        "acc = history.history[\"accuracy\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, \"r\", label=\"Training acc\")\n",
        "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
        "plt.title(\"Training and validation accuracy\")\n",
        "plt.ylabel(\"accuracy\") \n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"r\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.ylabel(\"loss\") \n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O25-WhFjTMD1",
        "outputId": "8a445a0d-a947-425a-db47-6257b7e681c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0126 - accuracy: 0.9767\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.012648353353142738, 0.9767441749572754]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "model.evaluate(test_data, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aexO462VTmEE",
        "outputId": "2b15d580-1c84-4498-d589-ddabbd0091aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rounded test_labels [[0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "preds=np.round(model.predict(test_data),0)\n",
        "print(\"rounded test_labels\", preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HimS-dWFVWVF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import itertools\n",
        "import keras\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img \n",
        "from keras.models import Sequential \n",
        "from keras import optimizers\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Dropout, Flatten, Dense \n",
        "from keras import applications \n",
        "from keras.utils.np_utils import to_categorical \n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "import math \n",
        "import datetime\n",
        "import time\n",
        "categorical_test_labels = pd.DataFrame(test_labels).idxmax(axis=1)\n",
        "categorical_preds = pd.DataFrame(preds).idxmax(axis=1)\n",
        "confusion_matrix= confusion_matrix(categorical_test_labels, categorical_preds)\n",
        "\n",
        "#To get better visual of the confusion matrix:\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "   normalize=False,\n",
        "   title=\"Confusion matrix\",\n",
        "   cmap=plt.cm.Blues):\n",
        " \n",
        "#Add Normalization Option\n",
        " #prints pretty confusion metric with normalization option ‘’’\n",
        "   if normalize:\n",
        "     cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
        "     print(\"Normalized confusion matrix\")\n",
        "   else:\n",
        "     print(\"Confusion matrix, without normalization\")\n",
        " \n",
        "# print(cm)\n",
        " \n",
        "   plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
        "   plt.title(title)\n",
        "   plt.colorbar()\n",
        "   tick_marks = np.arange(len(classes))\n",
        "   plt.xticks(tick_marks, classes, rotation=45)\n",
        "   plt.yticks(tick_marks, classes)\n",
        " \n",
        "   fmt = \".2f\" if normalize else \"d\"\n",
        "   thresh = cm.max() / 2.\n",
        "   for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "      plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        " \n",
        "   plt.tight_layout()\n",
        "   plt.ylabel(\"True label\")\n",
        "   plt.xlabel(\"Predicted label\")\n",
        "   plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "QD_qUcYCWre6",
        "outputId": "5abefabd-bdd1-46dc-9583-d22d0f303ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized confusion matrix\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_confusion_matrix(confusion_matrix, [\"Classes\"], normalize=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}